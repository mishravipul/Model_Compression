{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compression_kerasSurgen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuKkF9s1oF8W",
        "colab_type": "code",
        "outputId": "e352fcff-a906-43e9-8334-0ed244842983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#installing library for model compression\n",
        "pip install kerassurgeon"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kerassurgeon\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/e7/8adbef95f56e2349bf9faf2aec462dee0a38cec7cd6bfb8895de83706762/kerassurgeon-0.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from kerassurgeon) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.16.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.0.9)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->kerassurgeon) (1.2.1)\n",
            "Installing collected packages: kerassurgeon\n",
            "Successfully installed kerassurgeon-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-vDCW6noG7o",
        "colab_type": "code",
        "outputId": "dca7de02-8234-4d47-bf8c-7142ebaa48d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as k\n",
        "from keras.datasets import mnist\n",
        "\n",
        "batch_size = 256\n",
        "num_class = 10\n",
        "epochs = 2\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if k.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_class)\n",
        "y_test = keras.utils.to_categorical(y_test, num_class)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdgbs0sBWi0G",
        "colab_type": "code",
        "outputId": "38f65c5e-c11f-4125-c02d-85980bc8ae54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Model creation\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu',\n",
        "                     input_shape=input_shape))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_class, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHiyrTm7ov9O",
        "colab_type": "code",
        "outputId": "2cbb148d-09b2-44df-f21b-c766e27ca5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#model training and weight saving\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs, \n",
        "            verbose=1, \n",
        "            validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model_name = 'convnet'\n",
        "model.save('./{}.h5'.format(model_name))\n",
        "model.save_weights('./{}_weights.h5'.format(model_name))\n",
        "\n",
        "print()\n",
        "print(\"Model saved as {}.h5\".format(model_name))\n",
        "print(\"Weights also saved separately as {}_weights.h5\".format(model_name))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 172s 3ms/step - loss: 0.3788 - acc: 0.8822 - val_loss: 0.1008 - val_acc: 0.9684\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 173s 3ms/step - loss: 0.1097 - acc: 0.9672 - val_loss: 0.0568 - val_acc: 0.9811\n",
            "Test loss: 0.05676591616256628\n",
            "Test accuracy: 0.9811\n",
            "\n",
            "Model saved as convnet.h5\n",
            "Weights also saved separately as convnet_weights.h5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9HpVj4EphVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsWk73NQrj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload keras surgeon library\n",
        "\n",
        "from kerassurgeon import identify\n",
        "from keras.models import load_model\n",
        "from kerassurgeon.operations import delete_layer, insert_layer, delete_channels\n",
        "\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p47dWCdryZZ",
        "colab_type": "code",
        "outputId": "6a2bc424-cf36-445f-f293-f9f7b8f31152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#Load the saved model\n",
        "\n",
        "model = load_model('convnet.h5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIjU4Lsar2hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ioMHdmtsi4o",
        "colab_type": "code",
        "outputId": "8523e1a4-67e1-4c5b-a6a3-65ea7e51493f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#printing model layers detail\n",
        "print(model.layers)\n",
        "for i in range(len(model.layers)):\n",
        " if len(model.layers[i].get_weights())!=0:\n",
        "        print(\"Layer Number:\",i,\"Layer Shape: \",model.layers[i].get_weights()[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<keras.layers.convolutional.Conv2D object at 0x7f30d9fd7278>, <keras.layers.convolutional.Conv2D object at 0x7f30d9fd7438>, <keras.layers.pooling.MaxPooling2D object at 0x7f30d976fd30>, <keras.layers.core.Dropout object at 0x7f30d9fd75f8>, <keras.layers.core.Flatten object at 0x7f30d9786e48>, <keras.layers.core.Dense object at 0x7f30d9786be0>, <keras.layers.core.Dropout object at 0x7f30d975c6d8>, <keras.layers.core.Dense object at 0x7f30d975c358>]\n",
            "Layer Number: 0 Layer Shape:  (3, 3, 1, 32)\n",
            "Layer Number: 1 Layer Shape:  (3, 3, 32, 64)\n",
            "Layer Number: 5 Layer Shape:  (9216, 128)\n",
            "Layer Number: 7 Layer Shape:  (128, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2FU9IH_soKW",
        "colab_type": "code",
        "outputId": "9b62c6e4-18ed-4b32-bd69-22e274455cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Structural compression\n",
        "\n",
        "#Visualize model weights \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# load the model\n",
        "model = load_model('convnet.h5')\n",
        "\n",
        "#print(model.summary())\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "loss_before_compress = score[0]\n",
        "accuracy_before_compress = score[1]\n",
        "print('Test loss before compression:', loss_before_compress)\n",
        "print('Test accuracy before compression:', accuracy_before_compress)\n",
        "\n",
        "\n",
        "# load the weight of a Convolution layer 1\n",
        "# 0 for first layer, 1 for second layer\n",
        "\n",
        "w1 = model.layers[0].get_weights()\n",
        "#w2 = model.layers[1].get_weights()[0]\n",
        "#w1 = model.layers[5].get_weights()[0]\n",
        "#conv_layer_weights = [w1,w2]\n",
        "#conv_layer_weights = [w1]\n",
        "\n",
        "\n",
        "print(w1[0].shape)\n",
        "print('non zero weights',np.count_nonzero(w1[0]))\n",
        "\n",
        "\n",
        "th = np.mean(w1[0])\n",
        "print('Threshold',th)\n",
        "\n",
        "\n",
        "#print(conv_layer_weights)\n",
        "#if a weight is less than thresold then convert to zero\n",
        "\n",
        "w1[0][w1[0]<th]=0\n",
        "\n",
        "#print(w1)\n",
        "print(w1[0].shape)\n",
        "\n",
        "model.layers[0].set_weights(w1)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss Afeter compression:', score[0])\n",
        "print('Test accuracy after compression:', score[1])\n",
        "print('non zero weights', np.count_nonzero(w1[0]))\n",
        "\n",
        "\n",
        "print('Test loss before compression:', loss_before_compress)\n",
        "print('Test accuracy before compression:', accuracy_before_compress)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss before compression: 0.05676591616256628\n",
            "Test accuracy before compression: 0.9811\n",
            "(3, 3, 1, 32)\n",
            "non zero weights 288\n",
            "Threshold 0.0319021\n",
            "(3, 3, 1, 32)\n",
            "Test loss Afeter compression: 0.31668553807735444\n",
            "Test accuracy after compression: 0.9111\n",
            "non zero weights 151\n",
            "Test loss before compression: 0.05676591616256628\n",
            "Test accuracy before compression: 0.9811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr8eCbLWtp5-",
        "colab_type": "code",
        "outputId": "c6fc68c6-9ae7-4abb-c7d6-86bb8d868836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "#Weight prunning\n",
        "#Node prunning of fully connected layer\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "model = load_model('convnet.h5')\n",
        "print(model.summary())\n",
        "\n",
        "# get fully connected layer weight\n",
        "\n",
        "w1 = model.layers[5].get_weights()[0]\n",
        "#w2 = model.layers[1].get_weights()[0]\n",
        "\n",
        "#conv_layer_weights = [w1,w2]\n",
        "layer_weights = [w1]\n",
        "\n",
        "#calculating L1 norm for a layer of the model  \n",
        "\n",
        "for i in range(len(layer_weights)):\n",
        "  weight = layer_weights[i]\n",
        "  #print(weight)\n",
        "  weight_dict={}\n",
        "  \n",
        "  num_filter = len(weight[0,:])\n",
        "  #num_filter = len(weight[0,0,0,:])\n",
        "  for j in range(num_filter):\n",
        "    w_s=np.sum(abs(weight[:,j]))\n",
        "    #w_s=np.sum(abs(weight[:,:,:,j]))\n",
        "    #filt='filt_{}'.format(j)\n",
        "    weight_dict[j] = w_s\n",
        "  weight_dict_sort=sorted(weight_dict.items(),key=lambda kv:kv[1])\n",
        "  print('L1 normconv layer {}\\n'.format(i+1),weight_dict_sort)\n",
        " \n",
        "#get L1 norm value and plot it\n",
        "\n",
        "  weights_value=[]\n",
        "  for y in weight_dict_sort:\n",
        "    weights_value.append(y[1])\n",
        "  \n",
        "  xc= range(num_filter)\n",
        "  plt.figure(i+1, figsize=(7,5))\n",
        "  plt.plot(xc,weights_value)\n",
        "  plt.grid(True)\n",
        "  plt.style.use(['classic'])\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "L1 normconv layer 1\n",
            " [(79, 115.92192), (58, 116.68475), (114, 117.016785), (124, 117.604965), (38, 118.26395), (30, 119.18378), (1, 119.484085), (63, 119.77737), (73, 120.2218), (120, 122.46235), (8, 122.55827), (53, 122.727806), (74, 123.45749), (45, 123.51915), (121, 124.0987), (9, 124.1759), (112, 124.24993), (17, 124.679436), (123, 124.72749), (5, 125.0703), (106, 125.32442), (87, 125.611435), (101, 125.816025), (92, 126.02293), (59, 126.031075), (85, 126.749275), (39, 126.95861), (37, 127.21018), (10, 127.3659), (14, 127.55763), (82, 128.16399), (93, 128.3607), (84, 128.39441), (68, 128.4386), (126, 128.65767), (22, 128.7626), (18, 128.94499), (41, 129.24496), (122, 129.32826), (96, 129.6382), (21, 129.69305), (12, 129.7652), (27, 129.86055), (90, 129.98471), (110, 130.07257), (60, 130.15968), (83, 130.28305), (89, 130.33287), (3, 130.35391), (36, 130.40842), (66, 130.47798), (127, 130.48393), (49, 130.51968), (111, 130.54678), (34, 130.64552), (42, 130.65118), (23, 130.65276), (107, 131.01288), (86, 131.13208), (25, 131.13707), (33, 131.13922), (44, 131.26617), (70, 131.306), (65, 131.33011), (99, 131.35129), (32, 131.3976), (16, 131.69736), (78, 131.71512), (125, 131.72879), (113, 131.7514), (0, 131.7992), (40, 131.94035), (119, 132.02231), (2, 132.15443), (7, 132.20322), (76, 132.21915), (108, 132.23103), (56, 132.42894), (81, 132.58197), (57, 132.63512), (54, 132.75737), (55, 132.86319), (50, 132.86778), (69, 132.897), (88, 132.95282), (103, 133.02083), (67, 133.0612), (51, 133.07567), (24, 133.24951), (71, 133.25294), (20, 133.28569), (48, 133.30634), (29, 133.39049), (118, 133.40987), (115, 133.41058), (109, 133.45233), (102, 133.68954), (19, 133.73593), (104, 133.78261), (117, 133.88235), (15, 133.9036), (26, 133.97467), (116, 134.10785), (64, 134.1233), (13, 134.16565), (35, 134.29308), (97, 134.33247), (98, 134.4724), (61, 134.47678), (80, 134.537), (62, 134.55696), (91, 134.7907), (75, 134.85332), (94, 134.9163), (43, 134.94379), (6, 135.06302), (105, 135.43953), (72, 135.53828), (31, 135.65942), (47, 135.8998), (95, 135.90907), (52, 135.94397), (100, 136.12787), (77, 136.99057), (28, 137.05048), (46, 137.60165), (4, 138.45427), (11, 139.47217)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEyCAYAAACfw1XEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny2YpBRUSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eoL6-xt4W7T",
        "colab_type": "code",
        "outputId": "6a12dded-b91c-4f2d-8cc8-b076a65e0b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        " #Delete Nodes from the Model.\n",
        "  \n",
        "dense_1 = model.layers[5]\n",
        "\n",
        "#enter which node you wanted to delete\n",
        "\n",
        "model = delete_channels(model, dense_1, [3,38,83])\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss Afeter compression:', score[0])\n",
        "print('Test accuracy after compression:', score[1])\n",
        "\n",
        "\n",
        "print('Test loss before compression:', loss_before_compress)\n",
        "print('Test accuracy before compression:', accuracy_before_compress)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting 3/128 channels from layer: dense_1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 125)               1152125   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1260      \n",
            "=================================================================\n",
            "Total params: 1,172,201\n",
            "Trainable params: 1,172,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss Afeter compression: 0.058065688600158316\n",
            "Test accuracy after compression: 0.9806\n",
            "Test loss before compression: 0.05676591616256628\n",
            "Test accuracy before compression: 0.9811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdMzPvBGEVrA",
        "colab_type": "code",
        "outputId": "8d468513-f104-4090-f693-29844a93b4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.048280825416138394\n",
            "Test accuracy: 0.9839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd1wMMVozQvw",
        "colab_type": "code",
        "outputId": "fe791b28-7093-4996-9fc7-b7ab37c24ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "#Weight prunning\n",
        "#filter prunning of convolution layer\n",
        "\n",
        "model = load_model('convnet.h5')\n",
        "\n",
        "#w1 = model.layers[0].get_weights()[0]\n",
        "\n",
        "# 2nd layer in the model is convolution layer\n",
        "# getting weights of convolution layer\n",
        "w2 = model.layers[1].get_weights()[0]\n",
        "\n",
        "#conv_layer_weights = [w1,w2]\n",
        "conv_layer_weights = [w2]\n",
        "\n",
        "\n",
        "for i in range(len(conv_layer_weights)):\n",
        "  weight = conv_layer_weights[i]\n",
        "  #print(weight)\n",
        "  weight_dict={}\n",
        "  \n",
        "  #num_filter = len(weight[0,:])\n",
        "  num_filter = len(weight[0,0,0,:])\n",
        "  for j in range(num_filter):\n",
        "    #w_s=np.sum(abs(weight[:,j]))\n",
        "    #taking L1 norm of the weight\n",
        "    w_s=np.sum(abs(weight[:,:,:,j]))\n",
        "    weight_dict[j] = w_s\n",
        "  weight_dict_sort=sorted(weight_dict.items(),key=lambda kv:kv[1])\n",
        "  print('L1 normconv layer {}\\n'.format(i+1),weight_dict_sort)\n",
        "\n",
        "\n",
        "#select number of filter you want to prune\n",
        "\n",
        "n = 20\n",
        "x=[]\n",
        "\n",
        "for i in range(n):\n",
        "  x.append(weight_dict_sort[i][0])\n",
        "print(x)\n",
        "\n",
        "\n",
        "dense_1 = model.layers[1]\n",
        "model = delete_channels(model, dense_1, x)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss Afeter compression:', score[0])\n",
        "print('Test accuracy after compression:', score[1])\n",
        "\n",
        "\n",
        "print('Test loss before compression:', loss_before_compress)\n",
        "print('Test accuracy before compression:', accuracy_before_compress)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1 normconv layer 1\n",
            " [(19, 11.670492), (54, 11.691042), (7, 11.75297), (10, 12.128744), (47, 12.234194), (60, 12.317528), (32, 12.37105), (56, 12.390006), (0, 12.3949585), (50, 12.443481), (30, 12.450472), (22, 12.79537), (39, 12.851103), (52, 12.957601), (5, 12.98576), (42, 13.005476), (43, 13.011995), (4, 13.01382), (53, 13.024656), (46, 13.071514), (24, 13.148503), (28, 13.207314), (8, 13.213285), (55, 13.2518425), (26, 13.347278), (31, 13.40442), (25, 13.407949), (1, 13.473665), (29, 13.572489), (35, 13.59551), (16, 13.641783), (2, 13.880938), (45, 13.886072), (38, 13.995516), (51, 14.030996), (63, 14.044562), (13, 14.079163), (20, 14.186078), (23, 14.227537), (27, 14.262571), (17, 14.372299), (57, 14.52813), (9, 14.674097), (44, 14.714343), (11, 14.755711), (59, 14.794771), (48, 14.830628), (21, 14.924862), (49, 14.964878), (33, 15.026666), (37, 15.128296), (40, 15.153286), (12, 15.238215), (61, 15.360361), (58, 15.393203), (41, 15.525232), (18, 15.909038), (14, 15.987936), (34, 16.094542), (6, 16.120792), (62, 16.404036), (36, 16.844889), (15, 16.920425), (3, 17.067932)]\n",
            "[19, 54, 7, 10, 47, 60, 32, 56, 0, 50, 30, 22, 39, 52, 5, 42, 43, 4, 53, 46]\n",
            "Deleting 20/64 channels from layer: conv2d_2\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 44)        12716     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               811136    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 825,462\n",
            "Trainable params: 825,462\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss Afeter compression: 0.06268449464952573\n",
            "Test accuracy after compression: 0.979\n",
            "Test loss before compression: 0.05676591616256628\n",
            "Test accuracy before compression: 0.9811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4OJ-5WVEh-3",
        "colab_type": "code",
        "outputId": "aea95fa3-34ff-4b8e-c91e-2fd959e007da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        }
      },
      "source": [
        "#Delete weights from both fully conected layr and convolution layer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "model = load_model('convnet.h5')\n",
        "print(model.summary())\n",
        "\n",
        "#convolution Layer \n",
        "\n",
        "w2 = model.layers[1].get_weights()[0]\n",
        "\n",
        "conv_layer_weights = [w2]\n",
        "\n",
        "\n",
        "for i in range(len(conv_layer_weights)):\n",
        "  weight = conv_layer_weights[i]\n",
        "  #print(weight)\n",
        "  weight_dict={}\n",
        "  \n",
        "  #num_filter = len(weight[0,:])\n",
        "  num_filter = len(weight[0,0,0,:])\n",
        "  for j in range(num_filter):\n",
        "    #w_s=np.sum(abs(weight[:,j]))\n",
        "    #taking L1 norm of the weight\n",
        "    w_s=np.sum(abs(weight[:,:,:,j]))\n",
        "    weight_dict[j] = w_s\n",
        "  weight_dict_sort=sorted(weight_dict.items(),key=lambda kv:kv[1])\n",
        "  print('L1 normconv layer {}\\n'.format(i+1),weight_dict_sort)\n",
        "\n",
        "\n",
        "#select number of filter you want to prune\n",
        "\n",
        "n = 10\n",
        "y=[]\n",
        "\n",
        "for i in range(n):\n",
        "  y.append(weight_dict_sort[i][0])\n",
        "print(y)\n",
        "\n",
        "\n",
        "# get fully connected layer weight\n",
        "\n",
        "w1 = model.layers[5].get_weights()[0]\n",
        "#w2 = model.layers[1].get_weights()[0]\n",
        "\n",
        "#conv_layer_weights = [w1,w2]\n",
        "layer_weights = [w1]\n",
        "\n",
        "#calculating L1 norm for a layer of the model  \n",
        "\n",
        "for i in range(len(layer_weights)):\n",
        "  weight = layer_weights[i]\n",
        "  #print(weight)\n",
        "  weight_dict={}\n",
        "  \n",
        "  num_filter = len(weight[0,:])\n",
        "  #num_filter = len(weight[0,0,0,:])\n",
        "  for j in range(num_filter):\n",
        "    w_s=np.sum(abs(weight[:,j]))\n",
        "    #w_s=np.sum(abs(weight[:,:,:,j]))\n",
        "    #filt='filt_{}'.format(j)\n",
        "    weight_dict[j] = w_s\n",
        "  weight_dict_sort=sorted(weight_dict.items(),key=lambda kv:kv[1])\n",
        "  print('L1 normconv layer {}\\n'.format(i+1),weight_dict_sort)\n",
        "  \n",
        "n = 5\n",
        "x=[]\n",
        "\n",
        "for i in range(n):\n",
        "  x.append(weight_dict_sort[i][0])\n",
        "print(x)\n",
        "\n",
        "\n",
        "conv_1 = model.layers[1]\n",
        "model = delete_channels(model, conv_1, y)\n",
        "\n",
        "print(\"After Deleting convolution layer\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "dense_1 = model.layers[6]\n",
        "model = delete_channels(model, dense_1, x)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss Afeter compression:', score[0])\n",
        "print('Test accuracy after compression:', score[1])\n",
        "\n",
        "\n",
        "print('Test loss before compression:', loss_before_compress)\n",
        "print('Test accuracy before compression:', accuracy_before_compress)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "L1 normconv layer 1\n",
            " [(19, 11.670492), (54, 11.691042), (7, 11.75297), (10, 12.128744), (47, 12.234194), (60, 12.317528), (32, 12.37105), (56, 12.390006), (0, 12.3949585), (50, 12.443481), (30, 12.450472), (22, 12.79537), (39, 12.851103), (52, 12.957601), (5, 12.98576), (42, 13.005476), (43, 13.011995), (4, 13.01382), (53, 13.024656), (46, 13.071514), (24, 13.148503), (28, 13.207314), (8, 13.213285), (55, 13.2518425), (26, 13.347278), (31, 13.40442), (25, 13.407949), (1, 13.473665), (29, 13.572489), (35, 13.59551), (16, 13.641783), (2, 13.880938), (45, 13.886072), (38, 13.995516), (51, 14.030996), (63, 14.044562), (13, 14.079163), (20, 14.186078), (23, 14.227537), (27, 14.262571), (17, 14.372299), (57, 14.52813), (9, 14.674097), (44, 14.714343), (11, 14.755711), (59, 14.794771), (48, 14.830628), (21, 14.924862), (49, 14.964878), (33, 15.026666), (37, 15.128296), (40, 15.153286), (12, 15.238215), (61, 15.360361), (58, 15.393203), (41, 15.525232), (18, 15.909038), (14, 15.987936), (34, 16.094542), (6, 16.120792), (62, 16.404036), (36, 16.844889), (15, 16.920425), (3, 17.067932)]\n",
            "[19, 54, 7, 10, 47, 60, 32, 56, 0, 50]\n",
            "L1 normconv layer 1\n",
            " [(79, 115.92192), (58, 116.68475), (114, 117.016785), (124, 117.604965), (38, 118.26395), (30, 119.18378), (1, 119.484085), (63, 119.77737), (73, 120.2218), (120, 122.46235), (8, 122.55827), (53, 122.727806), (74, 123.45749), (45, 123.51915), (121, 124.0987), (9, 124.1759), (112, 124.24993), (17, 124.679436), (123, 124.72749), (5, 125.0703), (106, 125.32442), (87, 125.611435), (101, 125.816025), (92, 126.02293), (59, 126.031075), (85, 126.749275), (39, 126.95861), (37, 127.21018), (10, 127.3659), (14, 127.55763), (82, 128.16399), (93, 128.3607), (84, 128.39441), (68, 128.4386), (126, 128.65767), (22, 128.7626), (18, 128.94499), (41, 129.24496), (122, 129.32826), (96, 129.6382), (21, 129.69305), (12, 129.7652), (27, 129.86055), (90, 129.98471), (110, 130.07257), (60, 130.15968), (83, 130.28305), (89, 130.33287), (3, 130.35391), (36, 130.40842), (66, 130.47798), (127, 130.48393), (49, 130.51968), (111, 130.54678), (34, 130.64552), (42, 130.65118), (23, 130.65276), (107, 131.01288), (86, 131.13208), (25, 131.13707), (33, 131.13922), (44, 131.26617), (70, 131.306), (65, 131.33011), (99, 131.35129), (32, 131.3976), (16, 131.69736), (78, 131.71512), (125, 131.72879), (113, 131.7514), (0, 131.7992), (40, 131.94035), (119, 132.02231), (2, 132.15443), (7, 132.20322), (76, 132.21915), (108, 132.23103), (56, 132.42894), (81, 132.58197), (57, 132.63512), (54, 132.75737), (55, 132.86319), (50, 132.86778), (69, 132.897), (88, 132.95282), (103, 133.02083), (67, 133.0612), (51, 133.07567), (24, 133.24951), (71, 133.25294), (20, 133.28569), (48, 133.30634), (29, 133.39049), (118, 133.40987), (115, 133.41058), (109, 133.45233), (102, 133.68954), (19, 133.73593), (104, 133.78261), (117, 133.88235), (15, 133.9036), (26, 133.97467), (116, 134.10785), (64, 134.1233), (13, 134.16565), (35, 134.29308), (97, 134.33247), (98, 134.4724), (61, 134.47678), (80, 134.537), (62, 134.55696), (91, 134.7907), (75, 134.85332), (94, 134.9163), (43, 134.94379), (6, 135.06302), (105, 135.43953), (72, 135.53828), (31, 135.65942), (47, 135.8998), (95, 135.90907), (52, 135.94397), (100, 136.12787), (77, 136.99057), (28, 137.05048), (46, 137.60165), (4, 138.45427), (11, 139.47217)]\n",
            "[79, 58, 114, 124, 38]\n",
            "Deleting 10/64 channels from layer: conv2d_2\n",
            "After Deleting convolution layer\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 54)        15606     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               995456    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,012,672\n",
            "Trainable params: 1,012,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Deleting 5/128 channels from layer: dense_1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 54)        15606     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 123)               956571    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1240      \n",
            "=================================================================\n",
            "Total params: 973,737\n",
            "Trainable params: 973,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss Afeter compression: 0.05752852225657552\n",
            "Test accuracy after compression: 0.9811\n",
            "Test loss before compression: 0.05676591616256628\n",
            "Test accuracy before compression: 0.9811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOQJpAoQLoGX",
        "colab_type": "code",
        "outputId": "2da1a225-6387-485a-d10c-9b15cc236292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.04710421532569453\n",
            "Test accuracy: 0.9839\n",
            "(3, 3, 1, 32)\n",
            "288\n",
            "0.032692477\n",
            "(3, 3, 1, 32)\n",
            "Test loss: 0.13691150419712067\n",
            "Test accuracy: 0.9714\n",
            "154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MAbZnMsMZc3",
        "colab_type": "code",
        "outputId": "9600753e-f0f8-400c-f395-be93fe77dfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        }
      },
      "source": [
        "#Retrain model after deleting the weights and filter\n",
        "#Delete weights from both fully conected layr and convolution layer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "model = load_model('convnet.h5')\n",
        "print(model.summary())\n",
        "\n",
        "#convolution Layer \n",
        "\n",
        "w2 = model.layers[1].get_weights()[0]\n",
        "\n",
        "conv_layer_weights = [w2]\n",
        "\n",
        "\n",
        "for i in range(len(conv_layer_weights)):\n",
        "  weight = conv_layer_weights[i]\n",
        "  #print(weight)\n",
        "  weight_dict={}\n",
        "  \n",
        "  #num_filter = len(weight[0,:])\n",
        "  num_filter = len(weight[0,0,0,:])\n",
        "  for j in range(num_filter):\n",
        "    #w_s=np.sum(abs(weight[:,j]))\n",
        "    #taking L1 norm of the weight\n",
        "    w_s=np.sum(abs(weight[:,:,:,j]))\n",
        "    weight_dict[j] = w_s\n",
        "  weight_dict_sort=sorted(weight_dict.items(),key=lambda kv:kv[1])\n",
        "  print('L1 normconv layer {}\\n'.format(i+1),weight_dict_sort)\n",
        "\n",
        "\n",
        "#select number of filter you want to prune\n",
        "\n",
        "n = 10\n",
        "y=[]\n",
        "\n",
        "for i in range(n):\n",
        "  y.append(weight_dict_sort[i][0])\n",
        "print(y)\n",
        "\n",
        "\n",
        "# get fully connected layer weight\n",
        "\n",
        "w1 = model.layers[5].get_weights()[0]\n",
        "#w2 = model.layers[1].get_weights()[0]\n",
        "\n",
        "#conv_layer_weights = [w1,w2]\n",
        "layer_weights = [w1]\n",
        "\n",
        "#calculating L1 norm for a layer of the model  \n",
        "\n",
        "for i in range(len(layer_weights)):\n",
        "  weight = layer_weights[i]\n",
        "  #print(weight)\n",
        "  weight_dict={}\n",
        "  \n",
        "  num_filter = len(weight[0,:])\n",
        "  #num_filter = len(weight[0,0,0,:])\n",
        "  for j in range(num_filter):\n",
        "    w_s=np.sum(abs(weight[:,j]))\n",
        "    #w_s=np.sum(abs(weight[:,:,:,j]))\n",
        "    #filt='filt_{}'.format(j)\n",
        "    weight_dict[j] = w_s\n",
        "  weight_dict_sort=sorted(weight_dict.items(),key=lambda kv:kv[1])\n",
        "  print('L1 normconv layer {}\\n'.format(i+1),weight_dict_sort)\n",
        "  \n",
        "n = 5\n",
        "x=[]\n",
        "\n",
        "for i in range(n):\n",
        "  x.append(weight_dict_sort[i][0])\n",
        "print(x)\n",
        "\n",
        "\n",
        "conv_1 = model.layers[1]\n",
        "model = delete_channels(model, conv_1, y)\n",
        "\n",
        "\n",
        "dense_1 = model.layers[6]\n",
        "model = delete_channels(model, dense_1, x)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss Afeter compression:', score[0])\n",
        "print('Test accuracy after compression:', score[1])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs, \n",
        "            verbose=1, \n",
        "            validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print('Test loss Afeter compression and retraining:', score[0])\n",
        "print('Test accuracy after compression and retraining:', score[1])\n",
        "\n",
        "\n",
        "print('Test loss before compression:', loss_before_compress)\n",
        "print('Test accuracy before compression:', accuracy_before_compress)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "L1 normconv layer 1\n",
            " [(19, 11.670492), (54, 11.691042), (7, 11.75297), (10, 12.128744), (47, 12.234194), (60, 12.317528), (32, 12.37105), (56, 12.390006), (0, 12.3949585), (50, 12.443481), (30, 12.450472), (22, 12.79537), (39, 12.851103), (52, 12.957601), (5, 12.98576), (42, 13.005476), (43, 13.011995), (4, 13.01382), (53, 13.024656), (46, 13.071514), (24, 13.148503), (28, 13.207314), (8, 13.213285), (55, 13.2518425), (26, 13.347278), (31, 13.40442), (25, 13.407949), (1, 13.473665), (29, 13.572489), (35, 13.59551), (16, 13.641783), (2, 13.880938), (45, 13.886072), (38, 13.995516), (51, 14.030996), (63, 14.044562), (13, 14.079163), (20, 14.186078), (23, 14.227537), (27, 14.262571), (17, 14.372299), (57, 14.52813), (9, 14.674097), (44, 14.714343), (11, 14.755711), (59, 14.794771), (48, 14.830628), (21, 14.924862), (49, 14.964878), (33, 15.026666), (37, 15.128296), (40, 15.153286), (12, 15.238215), (61, 15.360361), (58, 15.393203), (41, 15.525232), (18, 15.909038), (14, 15.987936), (34, 16.094542), (6, 16.120792), (62, 16.404036), (36, 16.844889), (15, 16.920425), (3, 17.067932)]\n",
            "[19, 54, 7, 10, 47, 60, 32, 56, 0, 50]\n",
            "L1 normconv layer 1\n",
            " [(79, 115.92192), (58, 116.68475), (114, 117.016785), (124, 117.604965), (38, 118.26395), (30, 119.18378), (1, 119.484085), (63, 119.77737), (73, 120.2218), (120, 122.46235), (8, 122.55827), (53, 122.727806), (74, 123.45749), (45, 123.51915), (121, 124.0987), (9, 124.1759), (112, 124.24993), (17, 124.679436), (123, 124.72749), (5, 125.0703), (106, 125.32442), (87, 125.611435), (101, 125.816025), (92, 126.02293), (59, 126.031075), (85, 126.749275), (39, 126.95861), (37, 127.21018), (10, 127.3659), (14, 127.55763), (82, 128.16399), (93, 128.3607), (84, 128.39441), (68, 128.4386), (126, 128.65767), (22, 128.7626), (18, 128.94499), (41, 129.24496), (122, 129.32826), (96, 129.6382), (21, 129.69305), (12, 129.7652), (27, 129.86055), (90, 129.98471), (110, 130.07257), (60, 130.15968), (83, 130.28305), (89, 130.33287), (3, 130.35391), (36, 130.40842), (66, 130.47798), (127, 130.48393), (49, 130.51968), (111, 130.54678), (34, 130.64552), (42, 130.65118), (23, 130.65276), (107, 131.01288), (86, 131.13208), (25, 131.13707), (33, 131.13922), (44, 131.26617), (70, 131.306), (65, 131.33011), (99, 131.35129), (32, 131.3976), (16, 131.69736), (78, 131.71512), (125, 131.72879), (113, 131.7514), (0, 131.7992), (40, 131.94035), (119, 132.02231), (2, 132.15443), (7, 132.20322), (76, 132.21915), (108, 132.23103), (56, 132.42894), (81, 132.58197), (57, 132.63512), (54, 132.75737), (55, 132.86319), (50, 132.86778), (69, 132.897), (88, 132.95282), (103, 133.02083), (67, 133.0612), (51, 133.07567), (24, 133.24951), (71, 133.25294), (20, 133.28569), (48, 133.30634), (29, 133.39049), (118, 133.40987), (115, 133.41058), (109, 133.45233), (102, 133.68954), (19, 133.73593), (104, 133.78261), (117, 133.88235), (15, 133.9036), (26, 133.97467), (116, 134.10785), (64, 134.1233), (13, 134.16565), (35, 134.29308), (97, 134.33247), (98, 134.4724), (61, 134.47678), (80, 134.537), (62, 134.55696), (91, 134.7907), (75, 134.85332), (94, 134.9163), (43, 134.94379), (6, 135.06302), (105, 135.43953), (72, 135.53828), (31, 135.65942), (47, 135.8998), (95, 135.90907), (52, 135.94397), (100, 136.12787), (77, 136.99057), (28, 137.05048), (46, 137.60165), (4, 138.45427), (11, 139.47217)]\n",
            "[79, 58, 114, 124, 38]\n",
            "Deleting 10/64 channels from layer: conv2d_2\n",
            "Deleting 5/128 channels from layer: dense_1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1_input (InputLayer)  (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 54)        15606     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 123)               956571    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1240      \n",
            "=================================================================\n",
            "Total params: 973,737\n",
            "Trainable params: 973,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Test loss Afeter compression: 0.05752852225657552\n",
            "Test accuracy after compression: 0.9811\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 156s 3ms/step - loss: 0.0804 - acc: 0.9760 - val_loss: 0.0401 - val_acc: 0.9861\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 154s 3ms/step - loss: 0.0652 - acc: 0.9803 - val_loss: 0.0370 - val_acc: 0.9878\n",
            "Test loss Afeter compression and retraining: 0.037043766271305505\n",
            "Test accuracy after compression and retraining: 0.9878\n",
            "Test loss before compression: 0.05676591616256628\n",
            "Test accuracy before compression: 0.9811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NIkJCipLxX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}